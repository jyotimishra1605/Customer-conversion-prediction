{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a4c5fb",
   "metadata": {},
   "source": [
    "# Customer Conversion Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "543fec1c",
   "metadata": {},
   "source": [
    "1. import libraries\n",
    "2. import data\n",
    "3. Clean Data\n",
    "4. EDA\n",
    "5. Encode\n",
    "6. Split\n",
    "7. Balance\n",
    "8. Scale\n",
    "9. Modeling and Evaluation\n",
    "10. Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c9942",
   "metadata": {},
   "source": [
    "### 1. Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing libraries for pre-porocessing of our data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "#Importing libraries for plotting graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing Libaries for modeling and evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3584ec",
   "metadata": {},
   "source": [
    "### 2. Importing the dataset and displaying the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0671e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing my traing dataset and getting an intial look on how data looks\n",
    "act_data = pd.read_csv(\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\train.csv\")\n",
    "act_data = act_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f87161",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52084e00",
   "metadata": {},
   "source": [
    "### 3. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e42e2",
   "metadata": {},
   "source": [
    "##### 3.1 Finding missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c692ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding missing values in our data\n",
    "act_data.isnull().sum()\n",
    "#There are no missing values in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376c00a",
   "metadata": {},
   "source": [
    "##### 3.2 Finding and deleting duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1860e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding duplicate values and droping them\n",
    "act_data = act_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1feefb1",
   "metadata": {},
   "source": [
    "##### 3.3 Removing outliers from our numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6682fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding and clipping our data based on outliers using iqr technique\n",
    "for i in act_data.select_dtypes(include=['int64', 'float64']):\n",
    "        iqr = act_data[i].quantile(0.75) - act_data[i].quantile(0.25)\n",
    "        upper_threshold = act_data[i].quantile(0.75) + (1.5 * iqr) # q3 + 1.5iqr\n",
    "        lower_threshold = act_data[i].quantile(0.25) - (1.5 * iqr) # q1 - 1.5iqr\n",
    "        act_data = act_data.copy()\n",
    "        act_data[i] = act_data[i].clip(lower_threshold, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6856c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c7fef",
   "metadata": {},
   "source": [
    "##### 3.4 Handling invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ce41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency of unique elements in catogorical column\n",
    "cat_cols = act_data.select_dtypes(include=object).columns.tolist()\n",
    "(pd.DataFrame(act_data[cat_cols].melt(var_name='column', value_name='value').value_counts()).rename(columns={0: 'counts'}).sort_values(by=['column', 'counts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ee03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see in education_qual and job column their are few unknown elements which can be replaced with mode\n",
    "#Replacing unknown values in education_qual and job columns with mode\n",
    "act_data = act_data.copy()\n",
    "act_data['education_qual']=act_data['education_qual'].replace('unknown', act_data['education_qual'].mode()[0])\n",
    "act_data['job']=act_data['job'].replace('unknown', act_data['job'].mode()[0])\n",
    "\n",
    "#Also call_type and prev_outcome column have unknown values but their frequency is higher and can be treated as seprated element itself\n",
    "#Renaming the unknown values so as to better analyse and does not coincide with each other\n",
    "act_data['call_type']=act_data['call_type'].replace('unknown', 'unknown_call_type')\n",
    "act_data['prev_outcome']=act_data['prev_outcome'].replace('unknown', 'unknown_prev_outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61769f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency of unique elements in catogorical column after renaming\n",
    "cat_cols = act_data.select_dtypes(include=object).columns.tolist()\n",
    "(pd.DataFrame(act_data[cat_cols].melt(var_name='column', value_name='value').value_counts()).rename(columns={0: 'counts'}).sort_values(by=['column', 'counts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4173d4",
   "metadata": {},
   "source": [
    "### 4. Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a34bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature vs Target Plot\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16, 8), sharey=True)\n",
    "fig.suptitle('Feature vs Target')\n",
    "xc = 0\n",
    "yc = 0\n",
    "for i in act_data.columns[:-1]:\n",
    "    sns.scatterplot(data=act_data, x=i, y='y', hue='y', ax=axes[xc, yc])\n",
    "    yc = yc + 1\n",
    "    if yc == 5:\n",
    "        yc=0\n",
    "        xc=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catogorical data count plot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(25, 20), sharey=False)\n",
    "fig.suptitle('Feature vs Target')\n",
    "xc = 0\n",
    "yc = 0\n",
    "for i in act_data.select_dtypes(include=['object'], exclude=['int64', 'float64']).columns:\n",
    "    sns.countplot(x = i, data = act_data, hue='y', ax=axes[xc, yc])\n",
    "    yc = yc + 1\n",
    "    if yc == 3:\n",
    "        yc=0\n",
    "        xc=xc+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccfc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature vs Feature (only numeric)\n",
    "sns.pairplot(act_data, hue ='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f293f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in act_data.select_dtypes(include=['object'], exclude=['int64', 'float64']).columns[:-1]:\n",
    "    for j in act_data.select_dtypes(include=['object'], exclude=['int64', 'float64']).columns[:-1]:\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.subplot(121)\n",
    "        sns.countplot(data=act_data, x=i, hue=j)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bc58f",
   "metadata": {},
   "source": [
    "### 5. Encoding our categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea22596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in act_data.select_dtypes(include=['object'], exclude=['int64', 'float64']).columns[:-1]:\n",
    "    \n",
    "    # Get one hot encoding of job column\n",
    "    one_hot = pd.get_dummies(act_data[i])\n",
    "    # Drop column B as it is now encoded\n",
    "    act_data = act_data.drop(i,axis = 1)\n",
    "    # Join the encoded df\n",
    "    act_data = act_data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89796d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get label encoding for y column\n",
    "act_data[\"y\"] = act_data[\"y\"].map({\"yes\":1,\"no\":0}) #encoding binary class data (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531d168",
   "metadata": {},
   "source": [
    "### 6. Split the dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the dat into train and test\n",
    "x = act_data[['age', 'day', 'dur', 'num_calls', 'admin.', 'blue-collar','entrepreneur', 'housemaid', 'management', 'retired',\n",
    "              'self-employed','services', 'student', 'technician', 'unemployed', 'divorced','married', 'single', 'primary',\n",
    "              'secondary', 'tertiary', 'cellular','telephone', 'unknown_call_type', 'apr', 'aug', 'dec', 'feb', 'jan','jul',\n",
    "              'jun', 'mar', 'may', 'nov', 'oct', 'sep', 'failure', 'other','success', 'unknown_prev_outcome']].values\n",
    "\n",
    "y = act_data[['y']].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89f384",
   "metadata": {},
   "source": [
    "### 7. Balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balancing the dataset\n",
    "smt = SMOTEENN(sampling_strategy='all')\n",
    "x_train, y_train = smt.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6c157",
   "metadata": {},
   "source": [
    "### 8. Standardize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarize the dataset before fitting it into the model\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf550b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5f733c",
   "metadata": {},
   "source": [
    "### 9. Model, Loss, Learning, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    \n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_test = x_test\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        \n",
    "    def log_reg_model(self):\n",
    "\n",
    "        log_reg = LogisticRegression() # initialise the model\n",
    "        log_reg.fit(self.x_train, self.y_train) #training the data\n",
    "        y_pred = log_reg.predict_proba(self.x_test) #Predicting\n",
    "        roc = roc_auc_score(self.y_test, y_pred[:,1]) #Evaluation\n",
    "        return roc\n",
    "  \n",
    "\n",
    "    def knn_model(self):\n",
    "        \n",
    "        #Finding the best value for K hyper parameter based on higest cv score\n",
    "        '''\n",
    "        khp = 0\n",
    "        hcv = 0\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10]:\n",
    "            knn = KNeighborsClassifier(i) #initialising the model\n",
    "            knn.fit(x_train,y_train) # training the model\n",
    "            if np.mean(cross_val_score(knn, x_train, y_train, cv=10, scoring = \"roc_auc\")) > hcv:\n",
    "                hcv = np.mean(cross_val_score(knn, x_train, y_train, cv=10, scoring = \"roc_auc\"))\n",
    "                khp = i\n",
    "            else:\n",
    "                break\n",
    "        '''\n",
    "        #Input the kbest K value and fit the model\n",
    "        knn = KNeighborsClassifier(6)\n",
    "        knn.fit(x_train,y_train)\n",
    "        y_pred = knn.predict(x_test)\n",
    "        roc = roc_auc_score(y_test, y_pred)\n",
    "        \n",
    "        return roc\n",
    "\n",
    "    \n",
    "    def dec_tree_model(self):\n",
    "\n",
    "        dt = DecisionTreeClassifier(max_depth=9)\n",
    "        dt.fit(self.x_train, self.y_train)\n",
    "        y_pred = dt.predict(self.x_test)\n",
    "        roc = roc_auc_score(self.y_test, y_pred)\n",
    "        return roc\n",
    "    \n",
    "    def ens_model(self):\n",
    "\n",
    "        model1 = LogisticRegression(random_state=1)\n",
    "        model2 = tree.DecisionTreeClassifier(max_depth=9, random_state=1)\n",
    "        model3 = KNeighborsClassifier(6)\n",
    "        model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='soft') \n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        model.predict(self.x_test)\n",
    "        y_pred = model.predict_proba(self.x_test)\n",
    "        roc = roc_auc_score(self.y_test,y_pred[:,1])\n",
    "        return roc\n",
    "    \n",
    "    def rf_model(self):\n",
    "\n",
    "        rf = RandomForestClassifier(max_depth=10,n_estimators=100, max_features='sqrt')\n",
    "        rf.fit(self.x_train, self.y_train) \n",
    "        y_pred = rf.predict(self.x_test)\n",
    "        roc = roc_auc_score(self.y_test, y_pred)\n",
    "        return roc\n",
    "    \n",
    "    def xg_model(self):\n",
    "        \n",
    "        model = XGBClassifier(learning_rate=0.5,n_estimators=100,verbosity=None)\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        y_pred = model.predict(self.x_test)\n",
    "        roc = roc_auc_score(y_test, y_pred)\n",
    "        return roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174674b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clsmod = ClassificationModel(x_train, x_test, y_train, y_test) #Intialzie the class\n",
    "\n",
    "temp_dict = {}\n",
    "\n",
    "knn_score = clsmod.knn_model()\n",
    "temp_dict['KNN'] = knn_score\n",
    "\n",
    "log_reg_score = clsmod.log_reg_model()\n",
    "temp_dict['Logestic Regression'] = log_reg_score\n",
    "\n",
    "dec_score = clsmod.dec_tree_model()\n",
    "temp_dict['Decision Tree'] = dec_score\n",
    "\n",
    "ens_score = clsmod.ens_model()\n",
    "temp_dict['Ensemble'] = ens_score\n",
    "\n",
    "rf_score = clsmod.rf_model()\n",
    "temp_dict['Random Forest'] = rf_score\n",
    "\n",
    "xg_score = clsmod.xg_model()\n",
    "temp_dict['XGBoost'] = xg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd. DataFrame.from_dict(temp_dict, orient ='index', columns=['AUROC Score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef58248",
   "metadata": {},
   "source": [
    "### 10. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding feature imporatance using random forest classifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10,n_estimators=100, max_features='sqrt')\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "feat_labels = act_data.columns[1:]\n",
    "\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
    "                    feat_labels[sorted_indices[f]],\n",
    "                    importances[sorted_indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb281f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble model to present\n",
    "\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(max_depth=9, random_state=1)\n",
    "model3 = KNeighborsClassifier(6)\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='soft') \n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.predict(x_test)\n",
    "y_pred = model.predict_proba(x_test)\n",
    "roc = roc_auc_score(y_test,y_pred[:,1])\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16895001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
